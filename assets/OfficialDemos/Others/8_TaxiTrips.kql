#connect cluster("demo12.westus").database("Datasets")


//                    [\
//               .----' `-----.
//              //^^^^;;^^^^^^`\
//      _______//_____||_____()_\________
//     /212    :      : ___              `\
//    |>   ____;      ;  |/\><|   ____   _<)
//   {____/    \_________________/    \____}
//        \ '' /                 \ '' /
//         '--'                   '--'

// Microsoft Developer - IoT Show: https://youtu.be/2aOa_S3Up0A
// Azure Hour: https://youtu.be/D_AJk2lAepw

// nyc taxi dataset
// ~1.5B rows
Trips
| count


// time series chart
// number of rides by week
// query is running on 1.5 B rows
Trips
| where pickup_datetime between(datetime(2009-01-01) .. datetime(2018-07-01))
| make-series ridecount=count() on pickup_datetime from datetime(2009-01-01) to datetime(2018-07-01) step 7d
| render timechart 


// anomaly detection
Trips
| where pickup_datetime between(datetime(2009-01-01) .. datetime(2018-07-01))
| make-series ridecount=count() on pickup_datetime from datetime(2009-01-01) to datetime(2018-07-01) step 7d
| extend anomalies = series_decompose_anomalies(ridecount, 1)
| render anomalychart with(anomalycolumns=anomalies, title='anomalies on nyc taxi rides')


// regression analysis
Trips
| where pickup_datetime between(datetime(2009-01-01) .. datetime(2018-07-01))
| make-series ridecount=count() on pickup_datetime from datetime(2009-01-01) to datetime(2018-07-01) step 7d
| extend series_fit_2lines(ridecount)
| render timechart 



// private ride apps
FHV_Trips
| count 


// compare nyc taxi trend with app based rides (uber, lyft, etc)
// union of two large tables; 1.5B rows and 500M rows
union withsource=T Trips, FHV_Trips
| where pickup_datetime between (datetime(2009-01-01) .. datetime(2018-07-01))
| summarize count() by T, bin(pickup_datetime, 7d)
| render timechart


// forecasting
FHV_Trips
| where pickup_datetime between(datetime(2017-01-01) .. datetime(2018-07-01))
| make-series ridecount=count() on pickup_datetime from datetime(2017-01-01) to datetime(2018-07-01) step 1d
| extend forecast = series_decompose_forecast(ridecount, 28)
| render timechart with(title='Forecasting the next week by Time Series Decomposition')


////////////////
////////////////
////////////////


// python plugin
// invoke custom udf
OccupancyDetection
| extend cluster_id=double(null)
| invoke kmeans_sf_OccupDetc(5, pack_array("Temperature", "Humidity", "Light", "CO2", "HumidityRatio"), "cluster_id")
| sample 10


ML_Models


// historical scenerio
// query adls gen 2
external_table('TaxiRides')
| where pickup_datetime between(datetime(2017-01-01) .. datetime(2017-02-01))
| summarize count() by cab_type
| render piechart 


#connect cluster('help').database('samples')

//cab type over a month
external_table("TaxiRides")
| where pickup_datetime between (datetime(2017-01-01) .. datetime(2017-02-01))
| summarize  count() by cab_type, bin(pickup_datetime, 1d)
| render timechart


//comparing two weeks YoY
let Rides = (start:datetime, end:datetime)
{
    external_table("TaxiRides")
    | where pickup_datetime > start and pickup_datetime < end
    | extend Day=dayofmonth(pickup_datetime)
};
Rides(datetime(2017-12-23), datetime(2018-01-01)) 
| summarize Count_2017=count() by Day
| join (Rides(datetime(2016-12-23),datetime(2017-01-01))
| summarize  Count_2016=count() by Day) on Day
| project-away Day1 
| render columnchart

